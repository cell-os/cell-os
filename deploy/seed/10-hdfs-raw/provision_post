#!/bin/bash

export nn1_host=$(machine_for_role nucleus 1 host)
export nn2_host=$(machine_for_role nucleus 2 host)

cat >> /opt/cell/cluster/cluster.yaml <<-EOT
### HDFS setup
hadoop_version: 2.6.0-cdh5.4.2-adobe
hadoop_lzo_version: 0.4.20
nn1_host: ${nn1_host}
nn2_host: ${nn2_host}
zk_quorum:
EOT

zk-list-nodes | sed 's/,/\n/g' | sed 's/:.*$//g' | sed 's/^/-  /' >> /opt/cell/cluster/cluster.yaml

cat >> /opt/cell/cluster/cluster.yaml <<-EOT
hadoop.dfs.nameservice_id: "${cell_name}"
hadoop_data_nodes: []
hadoop_number_of_disks: $(/usr/local/bin/detect-and-mount-disks)
hadoop::historyserver_host: "${nn1_host}"
hadoop::proxyusers:
  - name: root
    groups: ['*']
    hosts:  ['*']
hadoop_data_nodes: []
EOT

module_name="10-hdfs-raw"

function wait_for_process() {
  local process_name=$1
  local max_attempts=$2
  local attempt=0
  while [ ! $(pgrep -f $1) ]; do
    sleep 1
    printf .
    attempt=$(($attempt + 1))
    if [[ $attempt -gt $max_attempts ]]; then
      echo "Timed out while waiting for ${process_name}"
      exit 1
    fi
  done
}

if [[ -f /opt/cell/etc/roles/nucleus ]]; then
  /usr/local/bin/provision puppet base,hadoop_2_namenode,hadoop_2,hadoop_2_journalnode

  export host=$(hostname -f)
  service hadoop-hdfs-journalnode start
  wait_for_process JournalNode 10
  filetool --touch /shared/setup/${full_cell_name}/zk/$host
  if [[ $host == $nn1_host ]]; then
    cmdwait "filetool --count /shared/setup/${full_cell_name}/zk/" "3"
    su --login hadoop -c "/home/hadoop/hadoop/bin/hdfs namenode -format -nonInteractive" &> hdfs-format-result
    format_successful=$?
    if [[ format_successful -eq 1 ]]; then
        # check if already formatted or otherwise fail
        grep -q "Running in non-interactive mode, and data appears to exist in Storage Directory" hdfs-format-result
        if [[ $? -ne 0 ]]; then
            cat hdfs-format-result
            exit 1 # provision script will mark as failed and retry
        fi
    fi

    # this only "formats" the zookeeper hadoop-ha dir if it doesn't exist
    # hence it would only fail if zk is down
    su --login hadoop -c "/home/hadoop/hadoop/bin/hdfs zkfc -formatZK -nonInteractive"
    systemctl start hadoop-hdfs-zkfc
    systemctl start hadoop-hdfs-namenode
    wait_for_process DFSZKFailoverController 10
    wait_for_process NameNode 10
    filetool --touch /shared/setup/${full_cell_name}/nn1
  fi

  if [[ $host == $nn2_host ]]; then
    cmdwait "filetool --count /shared/setup/${full_cell_name}/zk/" "3"
    cmdwait "filetool --count /shared/setup/${full_cell_name}/nn1" "1"
    su --login hadoop -c "/home/hadoop/hadoop/bin/hdfs namenode -bootstrapStandby -nonInteractive"
    systemctl start hadoop-hdfs-zkfc
    systemctl start hadoop-hdfs-namenode
    wait_for_process DFSZKFailoverController 10
    wait_for_process NameNode 10
    filetool --touch /shared/setup/${full_cell_name}/nn2
  fi
elif [[ -f /opt/cell/etc/roles/stateful-body ]]; then
  /usr/local/bin/provision puppet base,hadoop_2_datanode

  cmdwait "filetool --count /shared/setup/${full_cell_name}/nn2" "1"
  systemctl start hadoop-hdfs-datanode
else
  report_status "${module_name} skipped"
fi
